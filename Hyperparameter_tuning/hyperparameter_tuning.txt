What are Parameter
    adjusted to minimize the loss function and optimize predictions
    example:
        Coefficients in Linear Regression
        weights and biases in neural networks

What are Hyperparameters:
    setting defined before training that influence how the model learns from data
    not learned from the data but insteed control the training process

    example:
        tree depth
        learing rate 
        number of estimators

importance:
    why tune Hyperparameters
        impove model performance
        enhance efficiency
        adapt to problem specific needs

commen hyperparameters:
    Desition tree and random forest
        Max depth:Limits the depth of trees to avoid overfitiing
        Min sample split:
        no of estimators
    Gradient Boosting models
        learning rate(contibution of tree)
        subsample(fraction of training data)
        max depth(limits complexity of individual trees)

    Neural networks
        learning rate(step size for weight updates)
        no of layers:determine the depth of networks
        batch size:no of samples per gradient update     

GRID SEARCH 
    Method of hyperparameters tuning that systematically evaluates all possible combinations of hyperparameters value within specified grid   

    Working:
        define a range of values for each hyperparameter and evaluate the model on each combination of hyperparameter values
        train and evaluate the model on each combination of hyperparameter values
        select the combination that yields best performance

    what is Random Search :
        alternative method where hyperparameter combinations are sampled randomly from the specified ranges  

        working:
            define ranges or distributions for each hyperparameter
            randomly sample a specified number of combinations
            train and evaluate the model for each sampled combination 



BAYESIAN OPTIMIZATION:
    Advanced method for hyperparameter tuning that balances exploration and exploitation(refining promising region)
    uses a probablistic model to guide the Search for optimal hyperparameter

    working:
        surrogate model
            builds probablistic model of the objective function based on prior evaluations
        Acquisition Function  
            balances exploration & exploitation by choosing the next hyperparameter to evaluate based on predicted performanceand uncertainity  

        iterative Refinement
            updates the surrogate model after each evaluation,refining the Search

    it is efficent for high dimentional and expensive to evaluate function
    reduces the no of evaluations

    POPULAR LIBRARIES:
        Hyperopt
            simplifies basyesian optimization for hyperparameter tuning
            works with fmin to minimize objective functions over Parameterspace   

        Optuna   
            flexible and user-friendly library for hyperparameteroptimization
            supports dynamic Searchspaces and pruning of unpromising trials

        Exploration:
            Focuses on sampling hyperparameter from unexplores region
            useful for indentifying new areas of high potential
        Exploitation:
            focuses on refining the search around regionwith known high performance
            useful for fine-tuning near optimal hyperparameter

         Bayesian optimization Advantage:
            balances these approches using the acuisition function to minimizeunnecessary evaluations while improving results

